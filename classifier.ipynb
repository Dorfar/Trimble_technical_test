{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c278d0f5-ed2d-49e5-84ad-d1827d5d29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%rm` not found.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 : Tensorboard management\n",
    "\n",
    "%load_ext tensorboard\n",
    "import datetime, os\n",
    "%rm -rf logs/ # to clear previous logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bfdc4f6-02f0-43c9-b241-1203f0a30deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 123 images belonging to 2 classes.\n",
      "Found 30 images belonging to 2 classes.\n",
      "Data generators built successfully !\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 : Image data management\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Batch size\n",
    "BS = 8\n",
    "\n",
    "# Create image generators, with data augmentation\n",
    "datagenerator = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.4,\n",
    "                                   height_shift_range=0.4,\n",
    "                                   brightness_range=[0.2,1],\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=[0.5,2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "train_generator = datagenerator.flow_from_directory('dataset/train_images',\n",
    "                                                  target_size=(200,200),\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=BS,\n",
    "                                                  shuffle=True,\n",
    "                                                  color_mode='rgb',\n",
    "                                                  subset='training')\n",
    "\n",
    "validation_generator = datagenerator.flow_from_directory('dataset/train_images',\n",
    "                                                        target_size=(200,200),\n",
    "                                                        class_mode='categorical',\n",
    "                                                        batch_size=BS,\n",
    "                                                        shuffle=True,\n",
    "                                                        color_mode='rgb',\n",
    "                                                        subset='validation')\n",
    "\n",
    "\n",
    "print(\"Data generators built successfully !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a12d602b-75fe-4c48-a69f-a3d5a8fe85a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 [==============================] - 5s 276ms/step - loss: 0.9143 - accuracy: 0.5772 - val_loss: 0.6772 - val_accuracy: 0.7333\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.6740 - accuracy: 0.7154 - val_loss: 0.6647 - val_accuracy: 0.7333\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.6510 - accuracy: 0.7154 - val_loss: 0.6543 - val_accuracy: 0.7333\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.6408 - accuracy: 0.7154 - val_loss: 0.6457 - val_accuracy: 0.7333\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.6183 - accuracy: 0.7154 - val_loss: 0.6219 - val_accuracy: 0.7333\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.6102 - accuracy: 0.7154 - val_loss: 0.6049 - val_accuracy: 0.7333\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.5668 - accuracy: 0.7154 - val_loss: 0.5847 - val_accuracy: 0.7333\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.5651 - accuracy: 0.7073 - val_loss: 0.5832 - val_accuracy: 0.7333\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.5768 - accuracy: 0.7154 - val_loss: 0.5841 - val_accuracy: 0.7333\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.5505 - accuracy: 0.7154 - val_loss: 0.5846 - val_accuracy: 0.7333\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.5468 - accuracy: 0.7154 - val_loss: 0.5829 - val_accuracy: 0.7333\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.5574 - accuracy: 0.7154 - val_loss: 0.6067 - val_accuracy: 0.7333\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4674 - accuracy: 0.7154 - val_loss: 0.6728 - val_accuracy: 0.7333\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.4892 - accuracy: 0.7154 - val_loss: 0.6183 - val_accuracy: 0.7333\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.4893 - accuracy: 0.7154 - val_loss: 0.6592 - val_accuracy: 0.7333\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.5538 - accuracy: 0.7154 - val_loss: 0.6552 - val_accuracy: 0.7333\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.5017 - accuracy: 0.7154 - val_loss: 0.6981 - val_accuracy: 0.7333\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.5053 - accuracy: 0.7154 - val_loss: 0.6360 - val_accuracy: 0.7333\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.4766 - accuracy: 0.7805 - val_loss: 0.6725 - val_accuracy: 0.7333\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.4617 - accuracy: 0.7480 - val_loss: 0.6586 - val_accuracy: 0.7333\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.5139 - accuracy: 0.7561 - val_loss: 0.5524 - val_accuracy: 0.7333\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.4403 - accuracy: 0.8211 - val_loss: 0.7143 - val_accuracy: 0.7333\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.4649 - accuracy: 0.8049 - val_loss: 0.5270 - val_accuracy: 0.7667\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.4228 - accuracy: 0.8049 - val_loss: 0.5355 - val_accuracy: 0.7667\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4749 - accuracy: 0.7886 - val_loss: 0.5925 - val_accuracy: 0.7667\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4977 - accuracy: 0.7805 - val_loss: 0.5366 - val_accuracy: 0.7667\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4661 - accuracy: 0.7805 - val_loss: 0.6521 - val_accuracy: 0.7667\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.3930 - accuracy: 0.8211 - val_loss: 0.5704 - val_accuracy: 0.8000\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3958 - accuracy: 0.8049 - val_loss: 0.6300 - val_accuracy: 0.8000\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.4152 - accuracy: 0.8211 - val_loss: 0.6847 - val_accuracy: 0.7667\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.4020 - accuracy: 0.8211 - val_loss: 0.4450 - val_accuracy: 0.8333\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4224 - accuracy: 0.7724 - val_loss: 0.5224 - val_accuracy: 0.8333\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.4269 - accuracy: 0.8211 - val_loss: 0.5691 - val_accuracy: 0.7667\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.4554 - accuracy: 0.7724 - val_loss: 0.5649 - val_accuracy: 0.8333\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.4228 - accuracy: 0.8130 - val_loss: 0.4716 - val_accuracy: 0.8667\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.4973 - accuracy: 0.7886 - val_loss: 0.5387 - val_accuracy: 0.8000\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.4375 - accuracy: 0.8455 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.4146 - accuracy: 0.8293 - val_loss: 0.5934 - val_accuracy: 0.8000\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.4293 - accuracy: 0.8211 - val_loss: 0.6170 - val_accuracy: 0.7667\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.3992 - accuracy: 0.8211 - val_loss: 0.4590 - val_accuracy: 0.8667\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.4331 - accuracy: 0.8130 - val_loss: 0.5168 - val_accuracy: 0.8333\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.4280 - accuracy: 0.8211 - val_loss: 0.4717 - val_accuracy: 0.7667\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.4232 - accuracy: 0.8049 - val_loss: 0.5088 - val_accuracy: 0.8333\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.4491 - accuracy: 0.7805 - val_loss: 0.4494 - val_accuracy: 0.7667\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3995 - accuracy: 0.8211 - val_loss: 0.7141 - val_accuracy: 0.8000\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.4641 - accuracy: 0.8293 - val_loss: 0.5577 - val_accuracy: 0.7667\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4189 - accuracy: 0.7967 - val_loss: 0.5527 - val_accuracy: 0.7667\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.3790 - accuracy: 0.8293 - val_loss: 0.3913 - val_accuracy: 0.8333\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4267 - accuracy: 0.8455 - val_loss: 0.7218 - val_accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.4288 - accuracy: 0.8130 - val_loss: 0.6506 - val_accuracy: 0.7000\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3848 - accuracy: 0.8211 - val_loss: 0.6429 - val_accuracy: 0.7333\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3437 - accuracy: 0.8374 - val_loss: 0.6430 - val_accuracy: 0.7667\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.3922 - accuracy: 0.8130 - val_loss: 0.7122 - val_accuracy: 0.7667\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.3696 - accuracy: 0.8455 - val_loss: 0.6316 - val_accuracy: 0.7333\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3847 - accuracy: 0.8537 - val_loss: 0.5562 - val_accuracy: 0.8667\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.4046 - accuracy: 0.8130 - val_loss: 0.5392 - val_accuracy: 0.8333\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.5094 - accuracy: 0.7561 - val_loss: 0.5895 - val_accuracy: 0.8000\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.4256 - accuracy: 0.7805 - val_loss: 0.6064 - val_accuracy: 0.8000\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.4096 - accuracy: 0.8455 - val_loss: 0.4823 - val_accuracy: 0.8333\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.4207 - accuracy: 0.8293 - val_loss: 0.5099 - val_accuracy: 0.8000\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.4283 - accuracy: 0.7886 - val_loss: 0.5559 - val_accuracy: 0.7667\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.4552 - accuracy: 0.8130 - val_loss: 0.6778 - val_accuracy: 0.7333\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.4426 - accuracy: 0.7967 - val_loss: 0.6533 - val_accuracy: 0.8000\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.3839 - accuracy: 0.8211 - val_loss: 0.6297 - val_accuracy: 0.7000\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.4422 - accuracy: 0.7886 - val_loss: 0.5874 - val_accuracy: 0.7667\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4725 - accuracy: 0.8049 - val_loss: 0.4330 - val_accuracy: 0.8667\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.4304 - accuracy: 0.8293 - val_loss: 0.4795 - val_accuracy: 0.7667\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3649 - accuracy: 0.8455 - val_loss: 0.4559 - val_accuracy: 0.8667\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.4272 - accuracy: 0.7967 - val_loss: 0.5217 - val_accuracy: 0.8333\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.4169 - accuracy: 0.8211 - val_loss: 0.4113 - val_accuracy: 0.8333\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3981 - accuracy: 0.8049 - val_loss: 0.4884 - val_accuracy: 0.8333\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.4161 - accuracy: 0.8049 - val_loss: 0.5709 - val_accuracy: 0.8000\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.4143 - accuracy: 0.8049 - val_loss: 0.4515 - val_accuracy: 0.8667\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.3615 - accuracy: 0.8618 - val_loss: 0.5782 - val_accuracy: 0.7333\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3571 - accuracy: 0.8049 - val_loss: 0.5025 - val_accuracy: 0.8333\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.4602 - accuracy: 0.7561 - val_loss: 0.4876 - val_accuracy: 0.8333\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.4437 - accuracy: 0.7967 - val_loss: 0.4595 - val_accuracy: 0.8333\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4165 - accuracy: 0.8130 - val_loss: 0.5956 - val_accuracy: 0.8000\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.5056 - accuracy: 0.7724 - val_loss: 0.6365 - val_accuracy: 0.8333\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4248 - accuracy: 0.8211 - val_loss: 0.6392 - val_accuracy: 0.8000\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.4003 - accuracy: 0.8618 - val_loss: 0.5050 - val_accuracy: 0.8333\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.4836 - accuracy: 0.7967 - val_loss: 0.4039 - val_accuracy: 0.8667\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3796 - accuracy: 0.8374 - val_loss: 0.4869 - val_accuracy: 0.8333\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.4222 - accuracy: 0.8130 - val_loss: 0.5072 - val_accuracy: 0.8333\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.3226 - accuracy: 0.8618 - val_loss: 0.5109 - val_accuracy: 0.8333\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3932 - accuracy: 0.8130 - val_loss: 0.6261 - val_accuracy: 0.7667\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.4311 - accuracy: 0.8293 - val_loss: 0.5124 - val_accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3984 - accuracy: 0.8211 - val_loss: 0.3198 - val_accuracy: 0.8667\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.4224 - accuracy: 0.7805 - val_loss: 0.4377 - val_accuracy: 0.8333\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4837 - accuracy: 0.8049 - val_loss: 0.5028 - val_accuracy: 0.8000\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3643 - accuracy: 0.8130 - val_loss: 0.5139 - val_accuracy: 0.8333\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2895 - accuracy: 0.8618 - val_loss: 0.5529 - val_accuracy: 0.8333\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.4249 - accuracy: 0.7886 - val_loss: 0.6135 - val_accuracy: 0.8333\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3260 - accuracy: 0.8699 - val_loss: 0.3219 - val_accuracy: 0.8667\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4144 - accuracy: 0.8130 - val_loss: 0.7040 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.3625 - accuracy: 0.8211 - val_loss: 0.4683 - val_accuracy: 0.7667\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3480 - accuracy: 0.8293 - val_loss: 0.4548 - val_accuracy: 0.8000\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.3571 - accuracy: 0.8211 - val_loss: 0.3864 - val_accuracy: 0.8333\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3734 - accuracy: 0.8130 - val_loss: 0.5105 - val_accuracy: 0.7667\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.3464 - accuracy: 0.8130 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2569 - accuracy: 0.8862 - val_loss: 0.7269 - val_accuracy: 0.8333\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.3349 - accuracy: 0.8618 - val_loss: 0.6360 - val_accuracy: 0.8333\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3442 - accuracy: 0.8455 - val_loss: 0.5075 - val_accuracy: 0.8000\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.4425 - accuracy: 0.7967 - val_loss: 0.5677 - val_accuracy: 0.8333\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.4370 - accuracy: 0.7724 - val_loss: 0.4352 - val_accuracy: 0.8667\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.3341 - accuracy: 0.8211 - val_loss: 0.5833 - val_accuracy: 0.7667\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.3532 - accuracy: 0.8374 - val_loss: 0.3603 - val_accuracy: 0.8333\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.3766 - accuracy: 0.8618 - val_loss: 0.4076 - val_accuracy: 0.8333\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.4194 - accuracy: 0.8374 - val_loss: 0.3663 - val_accuracy: 0.8667\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3595 - accuracy: 0.8618 - val_loss: 0.5332 - val_accuracy: 0.8333\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3553 - accuracy: 0.8374 - val_loss: 0.5107 - val_accuracy: 0.8333\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.3313 - accuracy: 0.8780 - val_loss: 0.5007 - val_accuracy: 0.7667\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3953 - accuracy: 0.8455 - val_loss: 0.4042 - val_accuracy: 0.7667\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.3026 - accuracy: 0.8862 - val_loss: 0.4368 - val_accuracy: 0.8000\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.3583 - accuracy: 0.8780 - val_loss: 0.4594 - val_accuracy: 0.8333\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3767 - accuracy: 0.7967 - val_loss: 0.5125 - val_accuracy: 0.8000\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3568 - accuracy: 0.8293 - val_loss: 0.5195 - val_accuracy: 0.8333\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.5299 - accuracy: 0.7967 - val_loss: 0.4245 - val_accuracy: 0.7667\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.4263 - accuracy: 0.7967 - val_loss: 0.4078 - val_accuracy: 0.8333\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3743 - accuracy: 0.8130 - val_loss: 0.3722 - val_accuracy: 0.8333\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.3325 - accuracy: 0.8537 - val_loss: 0.6384 - val_accuracy: 0.8000\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3343 - accuracy: 0.8374 - val_loss: 0.5551 - val_accuracy: 0.8333\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.3353 - accuracy: 0.8537 - val_loss: 0.5378 - val_accuracy: 0.8000\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3288 - accuracy: 0.8862 - val_loss: 0.4238 - val_accuracy: 0.8333\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2903 - accuracy: 0.8618 - val_loss: 0.5217 - val_accuracy: 0.8333\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4069 - accuracy: 0.8374 - val_loss: 0.4207 - val_accuracy: 0.7667\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3061 - accuracy: 0.8862 - val_loss: 0.2941 - val_accuracy: 0.8000\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3736 - accuracy: 0.8537 - val_loss: 0.3376 - val_accuracy: 0.8333\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3244 - accuracy: 0.8293 - val_loss: 0.4417 - val_accuracy: 0.8667\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3762 - accuracy: 0.8537 - val_loss: 0.4781 - val_accuracy: 0.8667\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.3824 - accuracy: 0.8699 - val_loss: 0.4705 - val_accuracy: 0.8000\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3212 - accuracy: 0.8537 - val_loss: 0.3738 - val_accuracy: 0.8667\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3183 - accuracy: 0.8862 - val_loss: 0.3958 - val_accuracy: 0.8333\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.3710 - accuracy: 0.8455 - val_loss: 0.3984 - val_accuracy: 0.9000\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3302 - accuracy: 0.8455 - val_loss: 0.5266 - val_accuracy: 0.8333\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3163 - accuracy: 0.8455 - val_loss: 0.3760 - val_accuracy: 0.9000\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3442 - accuracy: 0.8293 - val_loss: 0.5890 - val_accuracy: 0.7667\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3907 - accuracy: 0.8211 - val_loss: 0.5594 - val_accuracy: 0.8000\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.4078 - accuracy: 0.8211 - val_loss: 0.4690 - val_accuracy: 0.8667\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.4381 - accuracy: 0.8374 - val_loss: 0.5029 - val_accuracy: 0.8333\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3801 - accuracy: 0.8211 - val_loss: 0.4171 - val_accuracy: 0.8667\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.3737 - accuracy: 0.8293 - val_loss: 0.4605 - val_accuracy: 0.8333\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3713 - accuracy: 0.8293 - val_loss: 0.2738 - val_accuracy: 0.9333\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.3470 - accuracy: 0.8618 - val_loss: 0.6347 - val_accuracy: 0.6667\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3028 - accuracy: 0.8699 - val_loss: 0.4498 - val_accuracy: 0.8333\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.2441 - accuracy: 0.8943 - val_loss: 0.4377 - val_accuracy: 0.8000\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.2906 - accuracy: 0.8780 - val_loss: 0.3462 - val_accuracy: 0.9000\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.3305 - accuracy: 0.8537 - val_loss: 0.4506 - val_accuracy: 0.8000\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.3054 - accuracy: 0.8780 - val_loss: 0.4489 - val_accuracy: 0.8333\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.2449 - accuracy: 0.8862 - val_loss: 0.4044 - val_accuracy: 0.8333\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3859 - accuracy: 0.8211 - val_loss: 0.4205 - val_accuracy: 0.8667\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2480 - accuracy: 0.8862 - val_loss: 0.5654 - val_accuracy: 0.8667\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2523 - accuracy: 0.8943 - val_loss: 0.5642 - val_accuracy: 0.8667\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3413 - accuracy: 0.8699 - val_loss: 0.2687 - val_accuracy: 0.9000\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.3134 - accuracy: 0.8699 - val_loss: 0.5760 - val_accuracy: 0.8667\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.3107 - accuracy: 0.8618 - val_loss: 0.5497 - val_accuracy: 0.8000\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.4175 - accuracy: 0.8374 - val_loss: 0.4901 - val_accuracy: 0.8333\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.3920 - accuracy: 0.8211 - val_loss: 0.4201 - val_accuracy: 0.8667\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.2967 - accuracy: 0.9024 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.2812 - accuracy: 0.8780 - val_loss: 0.5741 - val_accuracy: 0.8000\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3002 - accuracy: 0.9024 - val_loss: 0.3522 - val_accuracy: 0.8667\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.3255 - accuracy: 0.8618 - val_loss: 0.3325 - val_accuracy: 0.8667\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.3400 - accuracy: 0.8455 - val_loss: 0.3810 - val_accuracy: 0.8333\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2509 - accuracy: 0.8862 - val_loss: 0.3822 - val_accuracy: 0.8333\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.4310 - accuracy: 0.8293 - val_loss: 0.5540 - val_accuracy: 0.8333\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3753 - accuracy: 0.8618 - val_loss: 0.4158 - val_accuracy: 0.8000\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2742 - accuracy: 0.9106 - val_loss: 0.3941 - val_accuracy: 0.8667\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.4224 - accuracy: 0.8374 - val_loss: 0.5483 - val_accuracy: 0.8000\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.2950 - accuracy: 0.9024 - val_loss: 0.3853 - val_accuracy: 0.8333\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2974 - accuracy: 0.8537 - val_loss: 0.4831 - val_accuracy: 0.7333\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3263 - accuracy: 0.8618 - val_loss: 0.3534 - val_accuracy: 0.9000\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3062 - accuracy: 0.8943 - val_loss: 0.3470 - val_accuracy: 0.9000\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3195 - accuracy: 0.8618 - val_loss: 0.3407 - val_accuracy: 0.8333\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.3051 - accuracy: 0.8862 - val_loss: 0.5824 - val_accuracy: 0.7333\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2897 - accuracy: 0.8943 - val_loss: 0.4350 - val_accuracy: 0.8667\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.4257 - accuracy: 0.7886 - val_loss: 0.4765 - val_accuracy: 0.8333\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.2436 - accuracy: 0.9106 - val_loss: 0.5609 - val_accuracy: 0.8000\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3798 - accuracy: 0.8537 - val_loss: 0.4445 - val_accuracy: 0.8667\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3301 - accuracy: 0.8862 - val_loss: 0.5928 - val_accuracy: 0.8000\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.2914 - accuracy: 0.8780 - val_loss: 0.3199 - val_accuracy: 0.8667\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3098 - accuracy: 0.8780 - val_loss: 0.5330 - val_accuracy: 0.8000\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.2657 - accuracy: 0.9024 - val_loss: 0.3590 - val_accuracy: 0.9000\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3054 - accuracy: 0.8780 - val_loss: 0.6538 - val_accuracy: 0.7667\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.2381 - accuracy: 0.8780 - val_loss: 0.4229 - val_accuracy: 0.8667\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3367 - accuracy: 0.8455 - val_loss: 0.5928 - val_accuracy: 0.8333\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3926 - accuracy: 0.8862 - val_loss: 0.3740 - val_accuracy: 0.8667\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3197 - accuracy: 0.8618 - val_loss: 0.4591 - val_accuracy: 0.8333\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3726 - accuracy: 0.8699 - val_loss: 0.6005 - val_accuracy: 0.8667\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2550 - accuracy: 0.9024 - val_loss: 0.4948 - val_accuracy: 0.9000\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2784 - accuracy: 0.8699 - val_loss: 0.2592 - val_accuracy: 0.9000\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3437 - accuracy: 0.8780 - val_loss: 0.4482 - val_accuracy: 0.8667\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.2927 - accuracy: 0.8537 - val_loss: 0.4441 - val_accuracy: 0.8333\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3665 - accuracy: 0.8862 - val_loss: 0.5492 - val_accuracy: 0.8000\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3011 - accuracy: 0.8780 - val_loss: 0.2837 - val_accuracy: 0.9000\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.3749 - accuracy: 0.8455 - val_loss: 0.4552 - val_accuracy: 0.8000\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.2016 - accuracy: 0.9106 - val_loss: 0.6392 - val_accuracy: 0.7333\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3967 - accuracy: 0.8618 - val_loss: 0.4763 - val_accuracy: 0.8667\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.2040 - accuracy: 0.9512 - val_loss: 0.4581 - val_accuracy: 0.8333\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.3529 - accuracy: 0.8618 - val_loss: 0.4239 - val_accuracy: 0.8333\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.1978 - accuracy: 0.9106 - val_loss: 0.5101 - val_accuracy: 0.8000\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3100 - accuracy: 0.8780 - val_loss: 0.5162 - val_accuracy: 0.8000\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2726 - accuracy: 0.9106 - val_loss: 0.5387 - val_accuracy: 0.8000\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.2980 - accuracy: 0.8780 - val_loss: 0.4944 - val_accuracy: 0.8667\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3421 - accuracy: 0.8537 - val_loss: 0.4504 - val_accuracy: 0.9000\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.3770 - accuracy: 0.8699 - val_loss: 0.4424 - val_accuracy: 0.8333\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2843 - accuracy: 0.8780 - val_loss: 0.3718 - val_accuracy: 0.9000\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.3656 - accuracy: 0.8699 - val_loss: 0.3443 - val_accuracy: 0.9000\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.3470 - accuracy: 0.8049 - val_loss: 0.6068 - val_accuracy: 0.7667\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.3551 - accuracy: 0.8537 - val_loss: 0.4017 - val_accuracy: 0.8000\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.2510 - accuracy: 0.9024 - val_loss: 0.5807 - val_accuracy: 0.8000\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.3022 - accuracy: 0.9106 - val_loss: 0.4540 - val_accuracy: 0.8000\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.3298 - accuracy: 0.8699 - val_loss: 0.5032 - val_accuracy: 0.7667\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 5s 280ms/step - loss: 0.2944 - accuracy: 0.8455 - val_loss: 0.4302 - val_accuracy: 0.8333\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.3356 - accuracy: 0.8537 - val_loss: 0.4368 - val_accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 0.2336 - accuracy: 0.9024 - val_loss: 0.4997 - val_accuracy: 0.8333\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.2858 - accuracy: 0.8780 - val_loss: 0.5204 - val_accuracy: 0.8000\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 5s 309ms/step - loss: 0.2701 - accuracy: 0.9187 - val_loss: 0.3880 - val_accuracy: 0.9000\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.2344 - accuracy: 0.9024 - val_loss: 0.4774 - val_accuracy: 0.8000\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.2411 - accuracy: 0.9106 - val_loss: 0.4920 - val_accuracy: 0.8333\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.1591 - accuracy: 0.9187 - val_loss: 0.4457 - val_accuracy: 0.9000\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.3203 - accuracy: 0.8618 - val_loss: 0.5745 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.3422 - accuracy: 0.8699 - val_loss: 0.4230 - val_accuracy: 0.8667\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.2721 - accuracy: 0.9024 - val_loss: 0.5073 - val_accuracy: 0.8667\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.3714 - accuracy: 0.8211 - val_loss: 0.3664 - val_accuracy: 0.8667\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.2657 - accuracy: 0.9106 - val_loss: 0.6108 - val_accuracy: 0.7667\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2655 - accuracy: 0.8943 - val_loss: 0.7895 - val_accuracy: 0.7000\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.1775 - accuracy: 0.9268 - val_loss: 0.4362 - val_accuracy: 0.9000\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.3018 - accuracy: 0.8862 - val_loss: 0.4285 - val_accuracy: 0.8667\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.3218 - accuracy: 0.8537 - val_loss: 0.4165 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2847 - accuracy: 0.8943 - val_loss: 0.4310 - val_accuracy: 0.7667\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.2434 - accuracy: 0.9024 - val_loss: 0.3012 - val_accuracy: 0.9000\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3125 - accuracy: 0.8699 - val_loss: 0.5725 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.3221 - accuracy: 0.8699 - val_loss: 0.5018 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.2733 - accuracy: 0.9024 - val_loss: 0.5104 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.2577 - accuracy: 0.8862 - val_loss: 0.4408 - val_accuracy: 0.9000\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.3405 - accuracy: 0.8374 - val_loss: 0.6896 - val_accuracy: 0.8667\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.1818 - accuracy: 0.9268 - val_loss: 0.5707 - val_accuracy: 0.9000\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.2637 - accuracy: 0.8537 - val_loss: 0.4022 - val_accuracy: 0.9000\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.3689 - accuracy: 0.8455 - val_loss: 0.4209 - val_accuracy: 0.8333\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.3105 - accuracy: 0.8862 - val_loss: 0.3620 - val_accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2648 - accuracy: 0.9187 - val_loss: 0.5050 - val_accuracy: 0.8333\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3005 - accuracy: 0.8699 - val_loss: 0.2891 - val_accuracy: 0.9000\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2560 - accuracy: 0.8943 - val_loss: 0.4422 - val_accuracy: 0.8333\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.2808 - accuracy: 0.9106 - val_loss: 0.2775 - val_accuracy: 0.9000\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.2577 - accuracy: 0.8780 - val_loss: 0.4996 - val_accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3454 - accuracy: 0.8699 - val_loss: 0.3290 - val_accuracy: 0.9333\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3147 - accuracy: 0.8537 - val_loss: 0.4096 - val_accuracy: 0.8667\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.2781 - accuracy: 0.8780 - val_loss: 0.3707 - val_accuracy: 0.8667\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2037 - accuracy: 0.9024 - val_loss: 0.5818 - val_accuracy: 0.8667\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.1801 - accuracy: 0.9187 - val_loss: 0.4916 - val_accuracy: 0.8667\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.1451 - accuracy: 0.9350 - val_loss: 0.5156 - val_accuracy: 0.8667\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.4077 - accuracy: 0.8537 - val_loss: 0.5464 - val_accuracy: 0.8000\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.2242 - accuracy: 0.9024 - val_loss: 0.4558 - val_accuracy: 0.8667\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2542 - accuracy: 0.9106 - val_loss: 0.5314 - val_accuracy: 0.7667\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.1866 - accuracy: 0.9268 - val_loss: 0.6129 - val_accuracy: 0.8667\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2871 - accuracy: 0.8862 - val_loss: 0.4355 - val_accuracy: 0.8333\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2480 - accuracy: 0.9024 - val_loss: 0.2180 - val_accuracy: 0.9333\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.2957 - accuracy: 0.8943 - val_loss: 0.5734 - val_accuracy: 0.8333\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.3097 - accuracy: 0.8618 - val_loss: 0.8245 - val_accuracy: 0.7667\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2506 - accuracy: 0.8862 - val_loss: 0.4090 - val_accuracy: 0.8333\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.2441 - accuracy: 0.8862 - val_loss: 0.7538 - val_accuracy: 0.8000\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.2779 - accuracy: 0.8943 - val_loss: 0.3856 - val_accuracy: 0.8667\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.3243 - accuracy: 0.8618 - val_loss: 0.5707 - val_accuracy: 0.8000\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.3680 - accuracy: 0.8293 - val_loss: 0.4287 - val_accuracy: 0.8667\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3775 - accuracy: 0.8455 - val_loss: 0.4180 - val_accuracy: 0.8667\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3302 - accuracy: 0.8699 - val_loss: 0.4028 - val_accuracy: 0.9000\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.2946 - accuracy: 0.8780 - val_loss: 0.5050 - val_accuracy: 0.8000\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.2453 - accuracy: 0.9187 - val_loss: 0.4683 - val_accuracy: 0.8000\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 4s 242ms/step - loss: 0.2443 - accuracy: 0.9187 - val_loss: 0.2585 - val_accuracy: 0.9000\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.2737 - accuracy: 0.8943 - val_loss: 0.7002 - val_accuracy: 0.8333\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.3800 - accuracy: 0.8293 - val_loss: 0.5510 - val_accuracy: 0.8000\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2283 - accuracy: 0.9187 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.3643 - accuracy: 0.8455 - val_loss: 0.4162 - val_accuracy: 0.9000\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.3051 - accuracy: 0.8699 - val_loss: 0.5600 - val_accuracy: 0.7333\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.2234 - accuracy: 0.9106 - val_loss: 0.3753 - val_accuracy: 0.9333\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.2702 - accuracy: 0.9187 - val_loss: 0.4335 - val_accuracy: 0.8333\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 0.3110 - accuracy: 0.8699 - val_loss: 0.5643 - val_accuracy: 0.8000\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.2219 - accuracy: 0.9187 - val_loss: 0.6081 - val_accuracy: 0.8667\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.2169 - accuracy: 0.8943 - val_loss: 0.3519 - val_accuracy: 0.9000\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2327 - accuracy: 0.9106 - val_loss: 0.4984 - val_accuracy: 0.9000\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.2243 - accuracy: 0.9106 - val_loss: 0.5314 - val_accuracy: 0.8000\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.1844 - accuracy: 0.9024 - val_loss: 0.6040 - val_accuracy: 0.8667\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.1860 - accuracy: 0.9187 - val_loss: 0.6220 - val_accuracy: 0.8000\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 4s 244ms/step - loss: 0.3345 - accuracy: 0.8780 - val_loss: 0.5743 - val_accuracy: 0.8000\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3048 - accuracy: 0.8862 - val_loss: 0.6900 - val_accuracy: 0.8333\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 4s 229ms/step - loss: 0.3427 - accuracy: 0.8699 - val_loss: 0.3381 - val_accuracy: 0.8000\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2480 - accuracy: 0.8780 - val_loss: 0.3675 - val_accuracy: 0.9000\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2639 - accuracy: 0.8862 - val_loss: 0.3370 - val_accuracy: 0.8667\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2925 - accuracy: 0.9024 - val_loss: 0.3550 - val_accuracy: 0.9333\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.2252 - accuracy: 0.9106 - val_loss: 0.6370 - val_accuracy: 0.8667\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.2144 - accuracy: 0.9512 - val_loss: 0.5960 - val_accuracy: 0.8667\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 0.2128 - accuracy: 0.9106 - val_loss: 0.5566 - val_accuracy: 0.8333\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.1993 - accuracy: 0.9350 - val_loss: 0.3945 - val_accuracy: 0.8667\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.3224 - accuracy: 0.8780 - val_loss: 0.3331 - val_accuracy: 0.9000\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.2958 - accuracy: 0.8862 - val_loss: 0.4503 - val_accuracy: 0.8333\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.2655 - accuracy: 0.8862 - val_loss: 0.6899 - val_accuracy: 0.8000\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 0.2839 - accuracy: 0.8862 - val_loss: 0.4217 - val_accuracy: 0.9000\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 4s 241ms/step - loss: 0.2207 - accuracy: 0.9024 - val_loss: 0.3824 - val_accuracy: 0.9000\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.2938 - accuracy: 0.8943 - val_loss: 0.6114 - val_accuracy: 0.8333\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3163 - accuracy: 0.8618 - val_loss: 0.5118 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 : Model creation and fitting\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout,BatchNormalization,Activation\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "# Define training options\n",
    "EPOCHS=300\n",
    "lr = 0.01\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(4,(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(4,(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(8,(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(8,(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(16,(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(16,(3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "# Optimizer and model compilation\n",
    "opt = SGD(learning_rate=lr)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "# Define the log directory for tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "H = model.fit(train_generator,validation_data=validation_generator,epochs=EPOCHS,callbacks=[tensorboard_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0021b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 896), started 2:24:31 ago. (Use '!kill 896' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-21b7b6a27124d635\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-21b7b6a27124d635\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e88cb78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown `data_format`: tf. Expected one of {'channels_first', 'channels_last'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m K \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mbackend()\n\u001b[0;32m      9\u001b[0m \u001b[39mif\u001b[39;00m K\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     keras\u001b[39m.\u001b[39;49mbackend\u001b[39m.\u001b[39;49mset_image_data_format(\u001b[39m'\u001b[39;49m\u001b[39mtf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Save trained model (uncomment to save newly trained model)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend_config.py:153\u001b[0m, in \u001b[0;36mset_image_data_format\u001b[1;34m(data_format)\u001b[0m\n\u001b[0;32m    151\u001b[0m accepted_formats \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mchannels_last\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m data_format \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m accepted_formats:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown `data_format`: \u001b[39m\u001b[39m{\u001b[39;00mdata_format\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected one of \u001b[39m\u001b[39m{\u001b[39;00maccepted_formats\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    157\u001b[0m _IMAGE_DATA_FORMAT \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(data_format)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown `data_format`: tf. Expected one of {'channels_first', 'channels_last'}"
     ]
    }
   ],
   "source": [
    "# Cell 4 : Model saving, loading, and evaluation\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Save trained model (uncomment to save newly trained model)\n",
    "\n",
    "directory = \"./models/\"\n",
    "filename = 'trained_model_fields_and_roads.h5'\n",
    "#path = os.path.join(directory, filename)\n",
    "#model.save(path)\n",
    "#print('Trained model saved as %s' % path)\n",
    "\n",
    "# Load trained model (uncomment if model is not freshly trained)\n",
    "#model = load_model('./models/trained_model_fields_and_roads.h5')\n",
    "#print(\"Trained model loaded successfully !\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_generator = datagenerator.flow_from_directory('dataset/test_images',\n",
    "                                                 target_size=(200,200),\n",
    "                                                 batch_size=10,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=False,\n",
    "                                                 color_mode='rgb')\n",
    "\n",
    "# Confusion matrix \n",
    "\n",
    "Y_pred = model.predict(test_generator, verbose=1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "\n",
    "# First line of confusion matrix : true \"fields\" labels\n",
    "# Second line of confusion matrix : true \"roads\" labels\n",
    "# First column of confusion matrix : predicted \"fields\" labels\n",
    "# Second column of confusion matrix : predicted \"roads\" labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
